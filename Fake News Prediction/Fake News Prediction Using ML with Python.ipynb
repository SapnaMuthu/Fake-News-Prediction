{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5320df45",
   "metadata": {},
   "source": [
    "The News Dataset has the following attributes , they are:\n",
    "1. id: unique id for a news article \n",
    "2. title: title of the news article\n",
    "3. author: author of the news article\n",
    "4. text: text of the article \n",
    "5. label: a label that marks whether the news article is real or fake:\n",
    "   1 => fake news\n",
    "   0 => real news\n",
    "   \n",
    "Here we use the following tools:\n",
    ". NLTK - Natural Language ToolKit\n",
    ". Regular Expression\n",
    ". sklearn => TfidfVectorizer => to convert the text into the feature vectors (numbers)\n",
    "          => Logistic Regression is used since this problem is a binary classification Problem where the output can be either \n",
    "             a fake (1) or real (0) news.\n",
    "\n",
    "Basically this data is a text data and we need to convert the data into numeric data as a part of the preprocessing.\n",
    "\n",
    "The data set is extracted from Kaggle:\n",
    "https://www.kaggle.com/competitions/fake-news/data\n",
    "\n",
    "(use train.csv from the files present in the above link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d291d",
   "metadata": {},
   "source": [
    "# 1. Import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c408d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy is used for numerical calculations or to deal with the Numpy arrays\n",
    "# Pandas is used to deal with the dataframes\n",
    "# Regular Expressions are used to search through the text\n",
    "# NLTK is used ; corpus => the important context of the text ; stopwords => words that do not add value to the para ; \n",
    "# stemming is the process of extracting the root word from the word by removing their suffices and prefixes \n",
    "# TfidfVectorizer => used to convert the text into a feature vector\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd3dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\17347\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adb0f3",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bad18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\17347\\Sapna's Projects\\Fake News Prediction\\fake-news\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343b34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           id                                              title  \\\n",
      "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
      "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
      "2          2                  Why the Truth Might Get You Fired   \n",
      "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
      "4          4  Iranian woman jailed for fictional unpublished...   \n",
      "...      ...                                                ...   \n",
      "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
      "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
      "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
      "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
      "20799  20799                          What Keeps the F-35 Alive   \n",
      "\n",
      "                                          author  \\\n",
      "0                                  Darrell Lucus   \n",
      "1                                Daniel J. Flynn   \n",
      "2                             Consortiumnews.com   \n",
      "3                                Jessica Purkiss   \n",
      "4                                 Howard Portnoy   \n",
      "...                                          ...   \n",
      "20795                              Jerome Hudson   \n",
      "20796                           Benjamin Hoffman   \n",
      "20797  Michael J. de la Merced and Rachel Abrams   \n",
      "20798                                Alex Ansary   \n",
      "20799                              David Swanson   \n",
      "\n",
      "                                                    text  label  \n",
      "0      House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
      "1      Ever get the feeling your life circles the rou...      0  \n",
      "2      Why the Truth Might Get You Fired October 29, ...      1  \n",
      "3      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
      "4      Print \\nAn Iranian woman has been sentenced to...      1  \n",
      "...                                                  ...    ...  \n",
      "20795  Rapper T. I. unloaded on black celebrities who...      0  \n",
      "20796  When the Green Bay Packers lost to the Washing...      0  \n",
      "20797  The Macy’s of today grew from the union of sev...      0  \n",
      "20798  NATO, Russia To Hold Parallel Exercises In Bal...      1  \n",
      "20799    David Swanson is an author, activist, journa...      1  \n",
      "\n",
      "[20800 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dc9685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5338a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              title              author  \\\n",
      "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
      "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
      "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
      "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
      "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
      "\n",
      "                                                text  label  \n",
      "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
      "1  Ever get the feeling your life circles the rou...      0  \n",
      "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
      "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
      "4  Print \\nAn Iranian woman has been sentenced to...      1  \n"
     ]
    }
   ],
   "source": [
    "# to print the first 5 rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ecd1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of missing values in each column by using isnull()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9d178b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing the null values with the empty string\n",
    "df = df.fillna('')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b72af4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
      "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
      "2        Consortiumnews.com Why the Truth Might Get You...\n",
      "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
      "4        Howard Portnoy Iranian woman jailed for fictio...\n",
      "                               ...                        \n",
      "20795    Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...\n",
      "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
      "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
      "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
      "20799              David Swanson What Keeps the F-35 Alive\n",
      "Name: content, Length: 20800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#merging the title and the author name ; content data and the label are used to make the predictions\n",
    "df['content'] = df['author']+' '+df['title']\n",
    "print(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c772f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              title  \\\n",
      "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
      "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
      "2          2                  Why the Truth Might Get You Fired   \n",
      "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
      "4          4  Iranian woman jailed for fictional unpublished...   \n",
      "...      ...                                                ...   \n",
      "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
      "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
      "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
      "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
      "20799  20799                          What Keeps the F-35 Alive   \n",
      "\n",
      "                                          author  \\\n",
      "0                                  Darrell Lucus   \n",
      "1                                Daniel J. Flynn   \n",
      "2                             Consortiumnews.com   \n",
      "3                                Jessica Purkiss   \n",
      "4                                 Howard Portnoy   \n",
      "...                                          ...   \n",
      "20795                              Jerome Hudson   \n",
      "20796                           Benjamin Hoffman   \n",
      "20797  Michael J. de la Merced and Rachel Abrams   \n",
      "20798                                Alex Ansary   \n",
      "20799                              David Swanson   \n",
      "\n",
      "                                                    text  \\\n",
      "0      House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
      "1      Ever get the feeling your life circles the rou...   \n",
      "2      Why the Truth Might Get You Fired October 29, ...   \n",
      "3      Videos 15 Civilians Killed In Single US Airstr...   \n",
      "4      Print \\nAn Iranian woman has been sentenced to...   \n",
      "...                                                  ...   \n",
      "20795  Rapper T. I. unloaded on black celebrities who...   \n",
      "20796  When the Green Bay Packers lost to the Washing...   \n",
      "20797  The Macy’s of today grew from the union of sev...   \n",
      "20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
      "20799    David Swanson is an author, activist, journa...   \n",
      "\n",
      "                                                 content  \n",
      "0      Darrell Lucus House Dem Aide: We Didn’t Even S...  \n",
      "1      Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...  \n",
      "2      Consortiumnews.com Why the Truth Might Get You...  \n",
      "3      Jessica Purkiss 15 Civilians Killed In Single ...  \n",
      "4      Howard Portnoy Iranian woman jailed for fictio...  \n",
      "...                                                  ...  \n",
      "20795  Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...  \n",
      "20796  Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...  \n",
      "20797  Michael J. de la Merced and Rachel Abrams Macy...  \n",
      "20798  Alex Ansary NATO, Russia To Hold Parallel Exer...  \n",
      "20799            David Swanson What Keeps the F-35 Alive  \n",
      "\n",
      "[20800 rows x 5 columns]\n",
      "0        1\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "20795    0\n",
      "20796    0\n",
      "20797    0\n",
      "20798    1\n",
      "20799    1\n",
      "Name: label, Length: 20800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#seperating the data and the label \n",
    "# axis -> 0 ( row ) ; axis -> 1 ( column )\n",
    "x = df.drop(columns = 'label', axis = 1)\n",
    "y = df['label']\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ecdca7",
   "metadata": {},
   "source": [
    "# 2.1 Stemming:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ebac0a",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing a word to its root word by removing the suffixes and prefixes.\n",
    "\n",
    "Ex: actor , actress, acting --> act (root word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a51170",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stem  = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4575fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [porter_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea71d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        darrel lucu hous dem aid even see comey letter...\n",
      "1        daniel j flynn flynn hillari clinton big woman...\n",
      "2                   consortiumnew com truth might get fire\n",
      "3        jessica purkiss civilian kill singl us airstri...\n",
      "4        howard portnoy iranian woman jail fiction unpu...\n",
      "                               ...                        \n",
      "20795    jerom hudson rapper trump poster child white s...\n",
      "20796    benjamin hoffman n f l playoff schedul matchup...\n",
      "20797    michael j de la merc rachel abram maci said re...\n",
      "20798    alex ansari nato russia hold parallel exercis ...\n",
      "20799                            david swanson keep f aliv\n",
      "Name: content, Length: 20800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['content'] = df['content'].apply(stemming)\n",
    "print(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2afef195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['darrel lucu hous dem aid even see comey letter jason chaffetz tweet'\n",
      " 'daniel j flynn flynn hillari clinton big woman campu breitbart'\n",
      " 'consortiumnew com truth might get fire' ...\n",
      " 'michael j de la merc rachel abram maci said receiv takeov approach hudson bay new york time'\n",
      " 'alex ansari nato russia hold parallel exercis balkan'\n",
      " 'david swanson keep f aliv']\n",
      "[1 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#seperating the data and label \n",
    "x = df['content'].values\n",
    "y = df['label'].values\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9743f43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d522d1c",
   "metadata": {},
   "source": [
    "# 2.2 TfidfVectorizer -> to convert the text to a feature vector(number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83ffcd",
   "metadata": {},
   "source": [
    "Tf  -> Term Frequency -> Basically counts the number of times a word is repeating in the document ; repetition tells the model that it is the very important word and it assigns a particular numeric value to that word \n",
    "\n",
    "Idf -> Inverse Document Frequency -> A word which is repeated several times doesn't have meaning in it; when you conduct a movie review and if a movie review is repeated again and again in the collective positive and negative reviews ; the movie name doesn't add any meaning ; thus can be ignored \n",
    "Finds the word which are repeating so many times and it detects that those words are not significant and it reduces its importance value but the term frequency finds the number of significant words and it will give a particular value to it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821bdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the textual data to numerical data\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(x)\n",
    "#all the values in the content column will be converted to feature vectors ( numbers )\n",
    "x = vectorizer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd53a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15686)\t0.28485063562728646\n",
      "  (0, 13473)\t0.2565896679337957\n",
      "  (0, 8909)\t0.3635963806326075\n",
      "  (0, 8630)\t0.29212514087043684\n",
      "  (0, 7692)\t0.24785219520671603\n",
      "  (0, 7005)\t0.21874169089359144\n",
      "  (0, 4973)\t0.233316966909351\n",
      "  (0, 3792)\t0.2705332480845492\n",
      "  (0, 3600)\t0.3598939188262559\n",
      "  (0, 2959)\t0.2468450128533713\n",
      "  (0, 2483)\t0.3676519686797209\n",
      "  (0, 267)\t0.27010124977708766\n",
      "  (1, 16799)\t0.30071745655510157\n",
      "  (1, 6816)\t0.1904660198296849\n",
      "  (1, 5503)\t0.7143299355715573\n",
      "  (1, 3568)\t0.26373768806048464\n",
      "  (1, 2813)\t0.19094574062359204\n",
      "  (1, 2223)\t0.3827320386859759\n",
      "  (1, 1894)\t0.15521974226349364\n",
      "  (1, 1497)\t0.2939891562094648\n",
      "  (2, 15611)\t0.41544962664721613\n",
      "  (2, 9620)\t0.49351492943649944\n",
      "  (2, 5968)\t0.3474613386728292\n",
      "  (2, 5389)\t0.3866530551182615\n",
      "  (2, 3103)\t0.46097489583229645\n",
      "  :\t:\n",
      "  (20797, 13122)\t0.2482526352197606\n",
      "  (20797, 12344)\t0.27263457663336677\n",
      "  (20797, 12138)\t0.24778257724396507\n",
      "  (20797, 10306)\t0.08038079000566466\n",
      "  (20797, 9588)\t0.174553480255222\n",
      "  (20797, 9518)\t0.2954204003420313\n",
      "  (20797, 8988)\t0.36160868928090795\n",
      "  (20797, 8364)\t0.22322585870464118\n",
      "  (20797, 7042)\t0.21799048897828688\n",
      "  (20797, 3643)\t0.21155500613623743\n",
      "  (20797, 1287)\t0.33538056804139865\n",
      "  (20797, 699)\t0.30685846079762347\n",
      "  (20797, 43)\t0.29710241860700626\n",
      "  (20798, 13046)\t0.22363267488270608\n",
      "  (20798, 11052)\t0.4460515589182236\n",
      "  (20798, 10177)\t0.3192496370187028\n",
      "  (20798, 6889)\t0.32496285694299426\n",
      "  (20798, 5032)\t0.4083701450239529\n",
      "  (20798, 1125)\t0.4460515589182236\n",
      "  (20798, 588)\t0.3112141524638974\n",
      "  (20798, 350)\t0.28446937819072576\n",
      "  (20799, 14852)\t0.5677577267055112\n",
      "  (20799, 8036)\t0.45983893273780013\n",
      "  (20799, 3623)\t0.37927626273066584\n",
      "  (20799, 377)\t0.5677577267055112\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d46a87",
   "metadata": {},
   "source": [
    "Now, this transformed text data is going to be fed into the ML model in order to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f34eae",
   "metadata": {},
   "source": [
    "# 3. Splitting the dataset into training & test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e84b7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split : train -> 80% and test -> 20% ; stratify -> if you don't mention this stratify , then the real news and the \n",
    "#fake news won't be segregated in equal proportion and when you use stratify = y there will be a similar proportion as it was in\n",
    "#original dataset \n",
    "#random_state -> the random state function controls the shuffling process , it can be between 0 and 42 \n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size = 0.2, stratify = y , random_state = 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58290884",
   "metadata": {},
   "source": [
    "# 4. Training the Logistic Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51bd83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c833c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using model.fit()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228419e4",
   "metadata": {},
   "source": [
    "# 5. Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89152396",
   "metadata": {},
   "source": [
    "Accuracy Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef48718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the training data\n",
    "x_train_prediction = model.predict(x_train)\n",
    "training_data_accuracy = accuracy_score(x_train_prediction, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2adeb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the training data :  0.9865985576923076\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of the training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dad50033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the test data :  0.9790865384615385\n"
     ]
    }
   ],
   "source": [
    "# accuracy score on the test data\n",
    "x_test_prediction = model.predict(x_test)\n",
    "test_data_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c5549",
   "metadata": {},
   "source": [
    "# 6. Making a Predictive System:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f45dce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "The news is Fake\n"
     ]
    }
   ],
   "source": [
    "#x-new is the new news for which we're going to make a prediction; x_test[0] -> first news \n",
    "x_new = x_test[0]\n",
    "prediction = model.predict(x_new)\n",
    "print(prediction)\n",
    "\n",
    "if prediction[0] == 1:\n",
    "    print(\"The news is Fake\")\n",
    "else:\n",
    "    print(\"The news is Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afdfce12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d769b",
   "metadata": {},
   "source": [
    "Our model has predicted correctly for the first news item that the news is fake "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
